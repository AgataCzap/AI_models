{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgCjZm7C6VaU",
        "outputId": "95f08b81-49a7-48f1-e03e-9f77993072d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 64)]              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Francois Chollet's book - Deep Learning with Keras\n",
        "\n",
        "#sequential model used in previous examples is good, but quite limiting as it has only one input and one output of data\n",
        "#several layers of data processing and creating output data\n",
        "#can only process one data type, can be good for solving some problems but others are more complex\n",
        "#some problems such as predicting of online shopping behaviour requires multiple data inputs - numbers, videos, pictures, hashtags etc\n",
        "#some models allow non-linear crosslinking of different layers to enable data processing from multiple inputs, graphs of layers\n",
        "#joint training of model with different inputs instead of training individual separate models\n",
        "#some models may produce multiple outputs - date and genre of book being published\n",
        "#inception models - models trained on multiple convolution layers, the output is a tensor of all outputs combined\n",
        "#residual connections models - He in Microsoft, processed outputs of different models will be joined together to form new outputs, reduces loss of \n",
        "#already taught information, speeds up processing of complex data\n",
        "#adding API functional interface - individual layers of the model become functions that return tensors, processes tensors directly\n",
        "\n",
        "from keras import Input, layers\n",
        "input_tensor = Input(shape=(32,))\n",
        "dense = layers.Dense(32, activation='relu')\n",
        "output_tensor = dense(input_tensor)\n",
        "\n",
        "#creating simple sequential model that will be processed through the API interface\n",
        "from keras.models import Model, Sequential\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "seq_model = Sequential()\n",
        "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
        "seq_model.add(layers.Dense(32, activation='relu'))\n",
        "seq_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "input_tensor = Input(shape=(64,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
        "model = Model(input_tensor, output_tensor)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#keras usually on its own creates and inputs input and output tensors \n",
        "from keras.utils.np_utils import to_categorical\n",
        "model.compile(optimizer='rmsprop', loss='caterogical_crossentropy')\n",
        "#generating random inputs\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 64))\n",
        "y_train = np.random.random((1000, 10))\n",
        "\n",
        "#training model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
        "\n",
        "#evaluating the model\n",
        "score = model.evaluate(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "IcVcvz7jNgbK",
        "outputId": "c42d7d59-2f16-466e-b2d0-c5ef35355717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-61fde30dc1ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#evaluating the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 2367, in get\n        return deserialize(identifier)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 2322, in deserialize\n        return deserialize_keras_object(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: caterogical_crossentropy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#moving onto more code that actually works\n",
        "#keras model with multiple inputs, requires and a layer that combines these inputs/multiple tensors together known as keras.layers.add and keras.layers.concentrate\n",
        "#example model with 2 inputs, 1 input using natural language to ask a question, 2nd input collects information from articles to find the answer\n",
        "#model then tries to generate the answer to the question using the 2 inputs, usually one word using the softmax activation mode to generate a dictionary\n",
        "#model uses API functional interface\n",
        "#2 inputs are independent of each other, data from inputs are converted into vectors - dictionary of words, and a question formed by natural language\n",
        "#concatenated together and compiled with softmax classifactor\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#text input is a sequence of whole numbers, varying length, has to be named at the start\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "text_input = Input(shape=(None, ), dtype = 'int32', name='text')\n",
        "\n",
        "#setting input data into sequence vectors of size 64\n",
        "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
        "\n",
        "#saves text vectors into shared vector using LSTM shared layer\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "#same process to process questions, using different input layers\n",
        "question_input = Input(shape=(None, ), dtype='int32', name='question')\n",
        "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
        "encoded_question = layers.LSTM(32)(embedded_question)\n",
        "\n",
        "#concatenation of encoded dictionary and questions\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question], axis=1)\n",
        "\n",
        "#adding last classificator softmax\n",
        "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
        "\n",
        "#creating the model with 2 inputs and 1 output\n",
        "model = Model([text_input, question_input], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "#inputing data into the model, 2 ways to input data for training of model with 2 inputs\n",
        "#1st method is inputing data as Numpy tables \n",
        "#2nd method is giving dictionary that assigns Numpy tables to input data, requires labelling of input data\n",
        "import numpy as np\n",
        "num_samples = 1000\n",
        "max_length = 10\n",
        "\n",
        "#generating random input Numpy tables\n",
        "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
        "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
        "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
        "\n",
        "#tables are generated using hot one encoder, not whole numbers\n",
        "#fitting using list of input objects\n",
        "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
        "\n",
        "#fitting using dictionary of input objects, this method can only be used with input has labels\n",
        "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)\n",
        "\n",
        "#doesn't work as I am using CPU, if I used GPU then the graphic error input wouldn't appear\n",
        "#change size or change numbers assigned to nodes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ud_gi-9KjjM9",
        "outputId": "d843787b-6294-4563-8bb8-931b5ec7470d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-11a5c6ecf2ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#tables are generated using hot one encoder, not whole numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#fitting using list of input objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#fitting using dictionary of input objects, this method can only be used with input has labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_6/embedding_14/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-8-11a5c6ecf2ed>\", line 56, in <module>\n      model.fit([text, question], answers, epochs=10, batch_size=128)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/core/embedding.py\", line 199, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_6/embedding_14/embedding_lookup'\nindices[112,0] = 250 is not in [0, 64)\n\t [[{{node model_6/embedding_14/embedding_lookup}}]] [Op:__inference_train_function_31925]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model with multiple outputs\n",
        "#simple example is a model that tris to predict attributes of a person who anonimoyously posts on social media\n",
        "#different outputs can be different traits of this person - age, gender, income\n",
        "#still using keras API functional interface\n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras import Input\n",
        "\n",
        "\n",
        "vocabulary_size = 50000\n",
        "num_income_groups = 10\n",
        "\n",
        "posts_input = Input(shape=(None, ), dtype='int32', name='posts')\n",
        "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
        "\n",
        "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "#naming of the output layers\n",
        "age_prediction = layers.Dense(1, name='age')(x)\n",
        "income_prediction = layers.Dense(num_income_groups, \n",
        "                                 activation='softmax',\n",
        "                                 name='income')(x)\n",
        "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
        "\n",
        "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
        "\n",
        "#requires definition of loss of function for every output layer\n",
        "#definition of age requires scalar loss function, \n",
        "#gender is considered here as binary so binary loss of function\n",
        "#algorithm of gradient loss requires calculating scalar values and combining them together into one value\n",
        "#model with multiple outputs combines results of different loss of functions, keeps them and \n",
        "#saves a global loss value that will be minimised during training of the model\n",
        "#easiest way of combining is summing of different loss of functions using a compiler\n",
        "#many ways of summing all the loss of functions\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
        "\n",
        "#only use this formatting if output layers have been labelled\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss={'age': 'mse', 'income': 'categorical_crossentropy',\n",
        "                    'gender': 'binary_crossentropy'})\n",
        "\n",
        "\n",
        "#need to define loss value otherwise output layers will be trained to highest loss value\n",
        "#will cost data processing time and cause other problems\n",
        "#need to define scale/values of different loss functions by defining global loss value\n",
        "#scalar loss function calculating age, usually gives squared error values 3-5\n",
        "#binary crossentropy can only take values of 0 and 1\n",
        "#to resolve any issues and assign global value, assign value 10 to categorical crossentropy and squared error to 0.25\n",
        "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
        "              loss_weights=[0.25, 1, 10])\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss={'age': 'mse', 'income': 'categorical_crossentropy',\n",
        "                    'gender': 'binary_crossentropy'},\n",
        "              loss_weights={'age': 0.25, \n",
        "                            'gender': 1, \n",
        "                            'income': 10})\n",
        "\n",
        "#same as model with multiple inputs this model requires input of Numpy tables\n",
        "#using the Numpy tables created above\n",
        "model.fit(posts,[age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n",
        "\n",
        "model.fit(posts,{'age': age_targets, 'income': income_targets, 'gender': gender_targets}, epochs=10, batch_size=64)\n",
        "\n",
        "#cannot find all the Numpy tables, code to define these wasn't included\n"
      ],
      "metadata": {
        "id": "1anRhqcqxdia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "00d3dfc2-00c9-4a95-d9e5-07701a762d64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0539207c52db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#same as model with multiple inputs this model requires input of Numpy tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m#using the Numpy tables created above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposts_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mage_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincome_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_targets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposts_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mage_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'income'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mincome_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgender_targets\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'age_targets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#API interface also enables building of models that have multiple layers, not just inputs and outputs\n",
        "#allows complex model topology as long as the model is non-cyclic, does not allow for loops\n",
        "#tensor cannot be input into the same layer that created it\n",
        "#loops are only used to create re-current connections between convolutional layers\n",
        "#many famous types of models such as Inception and residual connection models\n",
        "#inception model - created by a group in Google, made up of several modules resembling small independent networks, usually 3 or 4 branches\n",
        "#inception model always starts with CNN 1x1 layer, followed by CNN 3x3 layer, last layer combines all the outputs together\n",
        "#makes it easier to train spatial and channel data, more complex Inception models can contain pooling layers and CNN layers with larger dimensions, e.g, 5x5\n",
        "#unlike with simple image processing model, instead of Dense layers to process data from previous layers, Inception uses convolutional point layers\n",
        "\n",
        "\n",
        "#every single layer has same number of steps which allows easy concatenation in the final layer\n",
        "#simple example of Inception model with 4 layers\n",
        "from keras import layers\n",
        "\n",
        "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
        "\n",
        "#spatial convolutional layer\n",
        "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
        "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
        "\n",
        "#using averaging method\n",
        "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
        "branch_c = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_c)\n",
        "\n",
        "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
        "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
        "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
        "\n",
        "#concatenation of the different layers located on independent branches\n",
        "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=1)\n",
        "\n",
        "#keras has dedicated library to inception models in keras.applications.inception_v3, \n",
        "#includes model for processing ImageNet pictures, and weights associated\n",
        "#also includes another library Xception, more extreme Inception models, modules are replaced with CNN followed by 1x1 point convolutional layers\n",
        "#allowing data to be input in every layer separately, faster processing of spatial data and channels, more efficient use of model parameters\n",
        "#same structure as Inception V3 model"
      ],
      "metadata": {
        "id": "2pRMwTOkLCeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#residual conncetions - used in many models after year 2015, invented by Microsoft, improves processing of data of large models (>10 layers)\n",
        "#resolves problems of large models such as disappearing gradient and narrow representations of output\n",
        "#residual connections work by converting data processed by previous layer as output representations of the next layer, summing and averaging these outputs\n",
        "#no concatenation between layers\n",
        "#usually assumed that all layers produce tensors with same dimensions, or uses linear transformation to change output dimensions\n",
        "#linear transformation can be done with Dense layer no activation or CNN 1x1 layer no activation\n",
        "\n",
        "#simple residual connection, assumes x is 4x4 tensor\n",
        "from keras import layers\n",
        "x = ...\n",
        "#transforming tensor x\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "\n",
        "#adds both tensors to make same dimensions\n",
        "y =layers.add([y, x])\n",
        "\n",
        "#now assuming that tensors have different dimensions\n",
        "x = ...\n",
        "#transforming tensor x\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "y = layers.MaxPooling2D(2, strides=2)(y)\n",
        "\n",
        "#1x1 CNN layer that performs linear transformation\n",
        "residual = layers.Conv2D(128, 1, padding='same', strides=2)(x)\n",
        "\n",
        "#adds both tensors with partial x tensor\n",
        "y =layers.add([y, residual])\n",
        "\n",
        "#narrow output problem = sequential models are based only on data processed by previous models, loss of data, only from activated layers, if\n",
        "#output tensor is small or layer has small dimensions then the following layer will have limited data to work with, residual connection resolves this\n",
        "#by passing by previous data before activated layers into the next layers"
      ],
      "metadata": {
        "id": "LMTgx8Vyq6VP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}